/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.0-torch1.10.0-cu111 is an invalid version and will not be supported in a future release
  warnings.warn(
/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.0-torch1.10.0-cu111 is an invalid version and will not be supported in a future release
  warnings.warn(
[2023-12-07 20:58:29,924][root][INFO] - Getting the dataset
[2023-12-07 20:58:29,924][root][INFO] - Transforms - Train True - Downstream True
{'voxel_decimation': 0.1, 'scaling_intensities': False, 'random_rotation_z': True, 'random_flip': True}
[2023-12-07 20:58:29,924][root][INFO] - Transforms - VoxelDecimation - 0.1
[2023-12-07 20:58:29,924][root][INFO] - Transforms - CreatePoints - npts 16384 - exact_number_of_points False - non_manifold None - non_manifold_dist 0.1
[2023-12-07 20:58:29,924][root][INFO] - Transforms - Axis 2 - ['pos', 'pos_non_manifold']
[2023-12-07 20:58:29,924][root][INFO] - Transforms - Flip
[2023-12-07 20:58:29,924][root][INFO] - CreateInputs -- ['pos', 'intensities']
[2023-12-07 20:58:29,924][root][INFO] - Transforms - Quantize - torchsparse
[2023-12-07 20:58:29,930][root][INFO] - Transforms - Train False - Downstream True
{'voxel_decimation': 0.1, 'scaling_intensities': False, 'random_rotation_z': True, 'random_flip': True}
[2023-12-07 20:58:29,930][root][INFO] - Transforms - VoxelDecimation - 0.1
[2023-12-07 20:58:29,931][root][INFO] - Transforms - CreatePoints - npts 16384 - exact_number_of_points False - non_manifold None - non_manifold_dist 0.1
[2023-12-07 20:58:29,931][root][INFO] - CreateInputs -- ['pos', 'intensities']
[2023-12-07 20:58:29,931][root][INFO] - Transforms - Quantize - torchsparse
======
Loading NuScenes tables for version v1.0-trainval...
Loading nuScenes-lidarseg...
32 category,
8 attribute,
4 visibility,
64386 instance,
12 sensor,
10200 calibrated_sensor,
2631083 ego_pose,
68 log,
850 scene,
34149 sample,
2631083 sample_data,
1166187 sample_annotation,
4 map,
34149 lidarseg,
Done loading in 33.074 seconds.
======
Reverse indexing ...
Done reverse indexing in 8.4 seconds.
======
[2023-12-07 20:59:11,424][root][INFO] - Nuscenes dataset - creating splits - split parametrizing
[2023-12-07 20:59:11,432][root][INFO] - Nuscenes dataset split parametrizing - 40 frames
======
Loading NuScenes tables for version v1.0-trainval...
Loading nuScenes-lidarseg...
32 category,
8 attribute,
4 visibility,
64386 instance,
12 sensor,
10200 calibrated_sensor,
2631083 ego_pose,
68 log,
850 scene,
34149 sample,
2631083 sample_data,
1166187 sample_annotation,
4 map,
34149 lidarseg,
Done loading in 29.823 seconds.
======
Reverse indexing ...
Done reverse indexing in 8.1 seconds.
======
[2023-12-07 20:59:49,356][root][INFO] - Nuscenes dataset - creating splits - split verifying
[2023-12-07 20:59:49,364][root][INFO] - Nuscenes dataset split verifying - 4021 frames
[2023-12-07 20:59:49,364][root][INFO] - Batch size - 2
[2023-12-07 20:59:49,365][root][INFO] - Creating trainer
[2023-12-07 20:59:49,365][root][INFO] - Savedir_root - ../output/minkunet_bevcontrast_ns/061223-1617/ckpt/Downstream/MinkUNet34_NuScenes_16384_parametrizingSplit_1000_0_model_e1.pt_inI_predI
/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:446: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.
  rank_zero_deprecation(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Missing logger folder: ../output/minkunet_bevcontrast_ns/061223-1617/ckpt/Downstream/MinkUNet34_NuScenes_16384_parametrizingSplit_1000_0_model_e1.pt_inI_predI/lightning_logs
[2023-12-07 20:59:52,962][root][INFO] - Saving at ../output/minkunet_bevcontrast_ns/061223-1617/ckpt/Downstream/MinkUNet34_NuScenes_16384_parametrizingSplit_1000_0_model_e1.pt_inI_predI/lightning_logs/version_0
[2023-12-07 20:59:53,451][root][INFO] - network - linear head
[2023-12-07 20:59:53,453][root][INFO] - Loading the weights from pretrained network
  key missing classifier.0.weight
  key missing classifier.0.bias
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [7]

  | Name      | Type             | Params
-----------------------------------------------
0 | net       | MinkUNet34       | 37.8 M
1 | criterion | CrossEntropyLoss | 0     
-----------------------------------------------
37.8 M    Trainable params
0         Non-trainable params
37.8 M    Total params
151.389   Total estimated model params size (MB)
2023-12-07 20:59:59.450520: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
[94mTrain Time: 2023-12-07 21:00:06.462483, Epoch 0 |miou:13.30 |fiou:45.27 |steps:20 |[0m
[94mTrain Time: 2023-12-07 21:00:11.883288, Epoch 1 |miou:16.51 |fiou:55.91 |steps:40 |[0m
[94mTrain Time: 2023-12-07 21:00:17.575194, Epoch 2 |miou:16.80 |fiou:58.96 |steps:60 |[0m
[94mTrain Time: 2023-12-07 21:00:23.087018, Epoch 3 |miou:18.59 |fiou:60.79 |steps:80 |[0m
[94mTrain Time: 2023-12-07 21:00:28.606384, Epoch 4 |miou:18.69 |fiou:60.83 |steps:100 |[0m
[94mTrain Time: 2023-12-07 21:00:34.632744, Epoch 5 |miou:20.19 |fiou:63.24 |steps:120 |[0m
[94mTrain Time: 2023-12-07 21:00:42.711002, Epoch 6 |miou:23.70 |fiou:67.48 |steps:140 |[0m
[94mTrain Time: 2023-12-07 21:00:49.695395, Epoch 7 |miou:25.48 |fiou:69.18 |steps:160 |[0m
[94mTrain Time: 2023-12-07 21:00:55.151326, Epoch 8 |miou:26.18 |fiou:68.91 |steps:180 |[0m
[94mTrain Time: 2023-12-07 21:01:00.565718, Epoch 9 |miou:28.23 |fiou:71.12 |steps:200 |[0m
[94mTrain Time: 2023-12-07 21:01:05.898750, Epoch 10 |miou:28.92 |fiou:71.64 |steps:220 |[0m
[94mTrain Time: 2023-12-07 21:01:11.607974, Epoch 11 |miou:31.33 |fiou:73.74 |steps:240 |[0m
[94mTrain Time: 2023-12-07 21:01:17.225040, Epoch 12 |miou:31.77 |fiou:73.95 |steps:260 |[0m
[94mTrain Time: 2023-12-07 21:01:22.777732, Epoch 13 |miou:34.11 |fiou:76.78 |steps:280 |[0m
[94mTrain Time: 2023-12-07 21:01:29.356930, Epoch 14 |miou:33.47 |fiou:75.27 |steps:300 |[0m
[94mTrain Time: 2023-12-07 21:01:35.822013, Epoch 15 |miou:34.45 |fiou:76.40 |steps:320 |[0m
[94mTrain Time: 2023-12-07 21:01:42.471373, Epoch 16 |miou:36.09 |fiou:77.94 |steps:340 |[0m
[94mTrain Time: 2023-12-07 21:01:48.058685, Epoch 17 |miou:36.31 |fiou:77.73 |steps:360 |[0m
[94mTrain Time: 2023-12-07 21:01:53.657660, Epoch 18 |miou:37.24 |fiou:79.27 |steps:380 |[0m
[94mTrain Time: 2023-12-07 21:01:59.108252, Epoch 19 |miou:37.89 |fiou:79.90 |steps:400 |[0m
[94mTrain Time: 2023-12-07 21:02:04.609040, Epoch 20 |miou:34.42 |fiou:76.16 |steps:420 |[0m
[94mTrain Time: 2023-12-07 21:02:10.915377, Epoch 21 |miou:35.08 |fiou:77.87 |steps:440 |[0m
[94mTrain Time: 2023-12-07 21:02:16.463752, Epoch 22 |miou:38.91 |fiou:80.36 |steps:460 |[0m
[94mTrain Time: 2023-12-07 21:02:21.897570, Epoch 23 |miou:39.58 |fiou:81.20 |steps:480 |[0m
[94mTrain Time: 2023-12-07 21:02:30.004824, Epoch 24 |miou:39.23 |fiou:80.09 |steps:500 |[0m
[94mTrain Time: 2023-12-07 21:02:35.631191, Epoch 25 |miou:40.92 |fiou:81.87 |steps:520 |[0m
[94mTrain Time: 2023-12-07 21:02:41.320427, Epoch 26 |miou:38.93 |fiou:81.73 |steps:540 |[0m
[94mTrain Time: 2023-12-07 21:02:46.849287, Epoch 27 |miou:35.66 |fiou:77.67 |steps:560 |[0m
[94mTrain Time: 2023-12-07 21:02:52.194659, Epoch 28 |miou:36.98 |fiou:80.08 |steps:580 |[0m
[94mTrain Time: 2023-12-07 21:02:57.889918, Epoch 29 |miou:37.41 |fiou:79.39 |steps:600 |[0m
[94mTrain Time: 2023-12-07 21:03:04.165287, Epoch 30 |miou:39.81 |fiou:80.92 |steps:620 |[0m
[94mTrain Time: 2023-12-07 21:03:12.294485, Epoch 31 |miou:41.64 |fiou:82.45 |steps:640 |[0m
[94mTrain Time: 2023-12-07 21:03:17.909737, Epoch 32 |miou:42.31 |fiou:83.47 |steps:660 |[0m
[94mTrain Time: 2023-12-07 21:03:23.273515, Epoch 33 |miou:43.00 |fiou:84.04 |steps:680 |[0m
[94mTrain Time: 2023-12-07 21:03:28.949883, Epoch 34 |miou:43.01 |fiou:84.11 |steps:700 |[0m
[94mTrain Time: 2023-12-07 21:03:34.376797, Epoch 35 |miou:46.32 |fiou:84.88 |steps:720 |[0m
[94mTrain Time: 2023-12-07 21:03:40.172482, Epoch 36 |miou:45.34 |fiou:84.90 |steps:740 |[0m
[94mTrain Time: 2023-12-07 21:03:45.940498, Epoch 37 |miou:46.52 |fiou:85.39 |steps:760 |[0m
[94mTrain Time: 2023-12-07 21:03:51.376222, Epoch 38 |miou:46.68 |fiou:85.64 |steps:780 |[0m
[94mTrain Time: 2023-12-07 21:04:00.523194, Epoch 39 |miou:47.67 |fiou:85.95 |steps:800 |[0m
[94mTrain Time: 2023-12-07 21:04:06.181841, Epoch 40 |miou:48.33 |fiou:86.25 |steps:820 |[0m
[94mTrain Time: 2023-12-07 21:04:11.632913, Epoch 41 |miou:49.06 |fiou:86.47 |steps:840 |[0m
[94mTrain Time: 2023-12-07 21:04:17.196375, Epoch 42 |miou:47.52 |fiou:85.96 |steps:860 |[0m
[94mTrain Time: 2023-12-07 21:04:22.764213, Epoch 43 |miou:46.65 |fiou:84.37 |steps:880 |[0m
[94mTrain Time: 2023-12-07 21:04:28.080481, Epoch 44 |miou:46.01 |fiou:84.31 |steps:900 |[0m
[94mTrain Time: 2023-12-07 21:04:33.512996, Epoch 45 |miou:48.86 |fiou:86.30 |steps:920 |[0m
[94mTrain Time: 2023-12-07 21:04:39.054840, Epoch 46 |miou:49.52 |fiou:86.43 |steps:940 |[0m
[94mTrain Time: 2023-12-07 21:04:45.601222, Epoch 47 |miou:49.94 |fiou:86.91 |steps:960 |[0m
[94mTrain Time: 2023-12-07 21:04:53.156803, Epoch 48 |miou:50.10 |fiou:86.73 |steps:980 |[0m
[94mTrain Time: 2023-12-07 21:04:59.122040, Epoch 49 |miou:50.87 |fiou:87.45 |steps:1000 |[0m
[94mTrain Time: 2023-12-07 21:05:04.751142, Epoch 50 |miou:51.64 |fiou:87.19 |steps:1020 |[0m
[94mTrain Time: 2023-12-07 21:05:10.255692, Epoch 51 |miou:51.63 |fiou:87.54 |steps:1040 |[0m
[94mTrain Time: 2023-12-07 21:05:15.785763, Epoch 52 |miou:51.17 |fiou:87.14 |steps:1060 |[0m
[94mTrain Time: 2023-12-07 21:05:21.491960, Epoch 53 |miou:52.94 |fiou:87.60 |steps:1080 |[0m
[94mTrain Time: 2023-12-07 21:05:27.088613, Epoch 54 |miou:53.04 |fiou:87.69 |steps:1100 |[0m
[94mTrain Time: 2023-12-07 21:05:32.382684, Epoch 55 |miou:53.42 |fiou:87.67 |steps:1120 |[0m
[94mTrain Time: 2023-12-07 21:05:39.922872, Epoch 56 |miou:53.76 |fiou:87.94 |steps:1140 |[0m
[94mTrain Time: 2023-12-07 21:05:46.372500, Epoch 57 |miou:54.27 |fiou:88.17 |steps:1160 |[0m
[94mTrain Time: 2023-12-07 21:05:51.757972, Epoch 58 |miou:55.71 |fiou:88.49 |steps:1180 |[0m
[94mTrain Time: 2023-12-07 21:05:57.132151, Epoch 59 |miou:53.60 |fiou:88.15 |steps:1200 |[0m
[94mTrain Time: 2023-12-07 21:06:02.821299, Epoch 60 |miou:53.69 |fiou:88.05 |steps:1220 |[0m
[94mTrain Time: 2023-12-07 21:06:08.613322, Epoch 61 |miou:55.70 |fiou:88.26 |steps:1240 |[0m
[94mTrain Time: 2023-12-07 21:06:14.072359, Epoch 62 |miou:55.89 |fiou:88.62 |steps:1260 |[0m
[94mTrain Time: 2023-12-07 21:06:19.582123, Epoch 63 |miou:56.65 |fiou:89.11 |steps:1280 |[0m
[94mTrain Time: 2023-12-07 21:06:26.286969, Epoch 64 |miou:56.36 |fiou:89.12 |steps:1300 |[0m
[94mTrain Time: 2023-12-07 21:06:33.479753, Epoch 65 |miou:57.06 |fiou:89.32 |steps:1320 |[0m
[94mTrain Time: 2023-12-07 21:06:38.988924, Epoch 66 |miou:58.71 |fiou:89.64 |steps:1340 |[0m
[94mTrain Time: 2023-12-07 21:06:44.679716, Epoch 67 |miou:56.83 |fiou:89.33 |steps:1360 |[0m
[94mTrain Time: 2023-12-07 21:06:50.085669, Epoch 68 |miou:57.26 |fiou:89.33 |steps:1380 |[0m
[94mTrain Time: 2023-12-07 21:06:55.987365, Epoch 69 |miou:57.98 |fiou:89.78 |steps:1400 |[0m
[94mTrain Time: 2023-12-07 21:07:01.451842, Epoch 70 |miou:58.30 |fiou:89.96 |steps:1420 |[0m
[94mTrain Time: 2023-12-07 21:07:06.971260, Epoch 71 |miou:57.68 |fiou:89.93 |steps:1440 |[0m
[94mTrain Time: 2023-12-07 21:07:13.357822, Epoch 72 |miou:58.73 |fiou:89.77 |steps:1460 |[0m
[94mTrain Time: 2023-12-07 21:07:21.584112, Epoch 73 |miou:59.06 |fiou:89.91 |steps:1480 |[0m
[94mTrain Time: 2023-12-07 21:07:27.178324, Epoch 74 |miou:59.01 |fiou:89.62 |steps:1500 |[0m
[94mTrain Time: 2023-12-07 21:07:32.987226, Epoch 75 |miou:59.21 |fiou:89.91 |steps:1520 |[0m
[94mTrain Time: 2023-12-07 21:07:38.565022, Epoch 76 |miou:58.38 |fiou:89.76 |steps:1540 |[0m
[94mTrain Time: 2023-12-07 21:07:44.043009, Epoch 77 |miou:58.87 |fiou:90.20 |steps:1560 |[0m
[94mTrain Time: 2023-12-07 21:07:49.452484, Epoch 78 |miou:60.81 |fiou:90.57 |steps:1580 |[0m
[94mTrain Time: 2023-12-07 21:07:55.073902, Epoch 79 |miou:60.53 |fiou:90.24 |steps:1600 |[0m
[94mTrain Time: 2023-12-07 21:08:02.858485, Epoch 80 |miou:58.51 |fiou:89.70 |steps:1620 |[0m
[94mTrain Time: 2023-12-07 21:08:09.592852, Epoch 81 |miou:58.67 |fiou:89.84 |steps:1640 |[0m
[94mTrain Time: 2023-12-07 21:08:15.407187, Epoch 82 |miou:60.68 |fiou:90.50 |steps:1660 |[0m
[94mTrain Time: 2023-12-07 21:08:20.946005, Epoch 83 |miou:56.52 |fiou:88.81 |steps:1680 |[0m
[94mTrain Time: 2023-12-07 21:08:26.328867, Epoch 84 |miou:49.74 |fiou:85.47 |steps:1700 |[0m
[94mTrain Time: 2023-12-07 21:08:31.802560, Epoch 85 |miou:47.40 |fiou:84.33 |steps:1720 |[0m
[94mTrain Time: 2023-12-07 21:08:37.404256, Epoch 86 |miou:52.25 |fiou:87.30 |steps:1740 |[0m
[94mTrain Time: 2023-12-07 21:08:43.021253, Epoch 87 |miou:53.22 |fiou:88.05 |steps:1760 |[0m
[94mTrain Time: 2023-12-07 21:08:48.563548, Epoch 88 |miou:56.70 |fiou:89.63 |steps:1780 |[0m
[94mTrain Time: 2023-12-07 21:08:57.603186, Epoch 89 |miou:59.32 |fiou:90.03 |steps:1800 |[0m
[94mTrain Time: 2023-12-07 21:09:03.479321, Epoch 90 |miou:60.04 |fiou:90.26 |steps:1820 |[0m
[94mTrain Time: 2023-12-07 21:09:09.149449, Epoch 91 |miou:59.96 |fiou:90.48 |steps:1840 |[0m
[94mTrain Time: 2023-12-07 21:09:14.645716, Epoch 92 |miou:58.91 |fiou:89.34 |steps:1860 |[0m
[94mTrain Time: 2023-12-07 21:09:20.014429, Epoch 93 |miou:59.72 |fiou:89.90 |steps:1880 |[0m
[94mTrain Time: 2023-12-07 21:09:25.478173, Epoch 94 |miou:59.55 |fiou:90.40 |steps:1900 |[0m
[94mTrain Time: 2023-12-07 21:09:31.127670, Epoch 95 |miou:62.26 |fiou:90.97 |steps:1920 |[0m
[94mTrain Time: 2023-12-07 21:09:36.655672, Epoch 96 |miou:62.17 |fiou:91.11 |steps:1940 |[0m
[94mTrain Time: 2023-12-07 21:09:44.785167, Epoch 97 |miou:62.91 |fiou:91.15 |steps:1960 |[0m
[94mTrain Time: 2023-12-07 21:09:51.622159, Epoch 98 |miou:62.61 |fiou:90.98 |steps:1980 |[0m
[92mVal Time: 2023-12-07 21:12:44.554546, Epoch 99 |miou:19.41 |fiou:54.37 |steps:2000 |[0m
[94mTrain Time: 2023-12-07 21:12:45.603971, Epoch 99 |miou:56.92 |fiou:88.39 |steps:2000 |[0m
[94mTrain Time: 2023-12-07 21:12:50.780608, Epoch 100 |miou:52.25 |fiou:87.18 |steps:2020 |[0m
[94mTrain Time: 2023-12-07 21:12:56.152924, Epoch 101 |miou:56.76 |fiou:89.22 |steps:2040 |[0m
[94mTrain Time: 2023-12-07 21:13:01.309773, Epoch 102 |miou:59.04 |fiou:90.47 |steps:2060 |[0m
[94mTrain Time: 2023-12-07 21:13:06.820351, Epoch 103 |miou:61.55 |fiou:91.10 |steps:2080 |[0m
[94mTrain Time: 2023-12-07 21:13:12.161968, Epoch 104 |miou:62.52 |fiou:91.51 |steps:2100 |[0m
[94mTrain Time: 2023-12-07 21:13:18.745894, Epoch 105 |miou:63.28 |fiou:91.39 |steps:2120 |[0m
[94mTrain Time: 2023-12-07 21:13:24.390962, Epoch 106 |miou:62.72 |fiou:91.74 |steps:2140 |[0m
[94mTrain Time: 2023-12-07 21:13:32.335709, Epoch 107 |miou:62.99 |fiou:91.32 |steps:2160 |[0m
[94mTrain Time: 2023-12-07 21:13:37.791281, Epoch 108 |miou:62.72 |fiou:91.33 |steps:2180 |[0m
[94mTrain Time: 2023-12-07 21:13:43.191991, Epoch 109 |miou:63.19 |fiou:91.45 |steps:2200 |[0m
[94mTrain Time: 2023-12-07 21:13:48.466828, Epoch 110 |miou:63.34 |fiou:91.83 |steps:2220 |[0m
[94mTrain Time: 2023-12-07 21:13:53.850475, Epoch 111 |miou:64.69 |fiou:92.14 |steps:2240 |[0m
[94mTrain Time: 2023-12-07 21:13:59.260219, Epoch 112 |miou:64.48 |fiou:91.95 |steps:2260 |[0m
[94mTrain Time: 2023-12-07 21:14:04.697444, Epoch 113 |miou:65.19 |fiou:92.03 |steps:2280 |[0m
[94mTrain Time: 2023-12-07 21:14:11.018533, Epoch 114 |miou:65.16 |fiou:92.30 |steps:2300 |[0m
[94mTrain Time: 2023-12-07 21:14:17.604021, Epoch 115 |miou:65.90 |fiou:92.39 |steps:2320 |[0m
[94mTrain Time: 2023-12-07 21:14:24.475906, Epoch 116 |miou:64.95 |fiou:91.99 |steps:2340 |[0m
[94mTrain Time: 2023-12-07 21:14:30.166068, Epoch 117 |miou:66.17 |fiou:92.29 |steps:2360 |[0m
[94mTrain Time: 2023-12-07 21:14:35.806312, Epoch 118 |miou:66.48 |fiou:92.46 |steps:2380 |[0m
[94mTrain Time: 2023-12-07 21:14:41.441150, Epoch 119 |miou:65.74 |fiou:92.39 |steps:2400 |[0m
[94mTrain Time: 2023-12-07 21:14:46.927119, Epoch 120 |miou:65.49 |fiou:92.39 |steps:2420 |[0m
[94mTrain Time: 2023-12-07 21:14:53.537135, Epoch 121 |miou:65.38 |fiou:92.29 |steps:2440 |[0m
[94mTrain Time: 2023-12-07 21:14:59.212713, Epoch 122 |miou:66.67 |fiou:92.49 |steps:2460 |[0m
[94mTrain Time: 2023-12-07 21:15:07.455436, Epoch 123 |miou:66.41 |fiou:92.75 |steps:2480 |[0m
[94mTrain Time: 2023-12-07 21:15:13.069705, Epoch 124 |miou:67.84 |fiou:92.81 |steps:2500 |[0m
[94mTrain Time: 2023-12-07 21:15:18.719970, Epoch 125 |miou:66.95 |fiou:92.90 |steps:2520 |[0m
[94mTrain Time: 2023-12-07 21:15:24.151622, Epoch 126 |miou:67.72 |fiou:93.00 |steps:2540 |[0m
[94mTrain Time: 2023-12-07 21:15:29.858738, Epoch 127 |miou:67.16 |fiou:92.72 |steps:2560 |[0m
[94mTrain Time: 2023-12-07 21:15:35.409237, Epoch 128 |miou:67.90 |fiou:92.85 |steps:2580 |[0m
[94mTrain Time: 2023-12-07 21:15:40.976905, Epoch 129 |miou:67.22 |fiou:92.49 |steps:2600 |[0m
[94mTrain Time: 2023-12-07 21:15:47.299626, Epoch 130 |miou:67.24 |fiou:92.93 |steps:2620 |[0m
[94mTrain Time: 2023-12-07 21:15:55.597470, Epoch 131 |miou:68.89 |fiou:92.97 |steps:2640 |[0m
[94mTrain Time: 2023-12-07 21:16:01.163735, Epoch 132 |miou:67.33 |fiou:92.94 |steps:2660 |[0m
[94mTrain Time: 2023-12-07 21:16:06.845045, Epoch 133 |miou:67.97 |fiou:93.02 |steps:2680 |[0m
[94mTrain Time: 2023-12-07 21:16:12.552927, Epoch 134 |miou:68.86 |fiou:92.91 |steps:2700 |[0m
[94mTrain Time: 2023-12-07 21:16:18.242829, Epoch 135 |miou:68.36 |fiou:93.17 |steps:2720 |[0m
[94mTrain Time: 2023-12-07 21:16:23.670268, Epoch 136 |miou:70.02 |fiou:93.21 |steps:2740 |[0m
[94mTrain Time: 2023-12-07 21:16:29.427667, Epoch 137 |miou:70.02 |fiou:93.33 |steps:2760 |[0m
[94mTrain Time: 2023-12-07 21:16:35.663981, Epoch 138 |miou:69.81 |fiou:93.20 |steps:2780 |[0m
[94mTrain Time: 2023-12-07 21:16:43.943799, Epoch 139 |miou:70.45 |fiou:93.39 |steps:2800 |[0m
[94mTrain Time: 2023-12-07 21:16:49.543897, Epoch 140 |miou:71.18 |fiou:93.39 |steps:2820 |[0m
[94mTrain Time: 2023-12-07 21:16:55.143659, Epoch 141 |miou:69.42 |fiou:93.25 |steps:2840 |[0m
[94mTrain Time: 2023-12-07 21:17:00.979407, Epoch 142 |miou:70.62 |fiou:93.31 |steps:2860 |[0m
[94mTrain Time: 2023-12-07 21:17:06.637212, Epoch 143 |miou:68.36 |fiou:93.21 |steps:2880 |[0m
[94mTrain Time: 2023-12-07 21:17:12.453673, Epoch 144 |miou:70.30 |fiou:93.22 |steps:2900 |[0m
[94mTrain Time: 2023-12-07 21:17:18.649428, Epoch 145 |miou:71.98 |fiou:93.41 |steps:2920 |[0m
[94mTrain Time: 2023-12-07 21:17:24.591348, Epoch 146 |miou:70.66 |fiou:93.49 |steps:2940 |[0m
[94mTrain Time: 2023-12-07 21:17:31.979762, Epoch 147 |miou:72.39 |fiou:93.65 |steps:2960 |[0m
[94mTrain Time: 2023-12-07 21:17:37.817768, Epoch 148 |miou:72.05 |fiou:93.49 |steps:2980 |[0m
[94mTrain Time: 2023-12-07 21:17:43.534222, Epoch 149 |miou:72.31 |fiou:93.77 |steps:3000 |[0m
[94mTrain Time: 2023-12-07 21:17:49.078241, Epoch 150 |miou:70.44 |fiou:93.36 |steps:3020 |[0m
[94mTrain Time: 2023-12-07 21:17:54.785857, Epoch 151 |miou:71.78 |fiou:93.34 |steps:3040 |[0m
[94mTrain Time: 2023-12-07 21:18:00.101710, Epoch 152 |miou:71.84 |fiou:93.55 |steps:3060 |[0m
[94mTrain Time: 2023-12-07 21:18:06.517883, Epoch 153 |miou:73.29 |fiou:93.58 |steps:3080 |[0m
[94mTrain Time: 2023-12-07 21:18:12.006810, Epoch 154 |miou:71.13 |fiou:93.57 |steps:3100 |[0m
[94mTrain Time: 2023-12-07 21:18:20.173581, Epoch 155 |miou:71.93 |fiou:93.84 |steps:3120 |[0m
[94mTrain Time: 2023-12-07 21:18:26.250248, Epoch 156 |miou:71.14 |fiou:93.84 |steps:3140 |[0m
Error executing job with overrides: ['cfg=nuscenes_torchsparse', 'cfg.downstream.max_epochs=1000', 'cfg.downstream.val_interval=100', 'cfg.downstream.skip_ratio=1000', 'cfg.downstream.batch_size=2', 'cfg.downstream.checkpoint_dir=../output/minkunet_bevcontrast_ns/061223-1617/ckpt/', 'cfg.downstream.checkpoint_name=model_e1.pt']
Traceback (most recent call last):
  File "/public/sdc/yfzhang/git_sdc/BEVContrast/downstream/train_downstream_semseg.py", line 330, in main
    trainer.fit(model, train_loader, val_loader, ckpt_path=config["resume"])
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 696, in fit
    self._call_and_handle_interrupt(
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 737, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1168, in _run
    results = self._run_stage()
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1254, in _run_stage
    return self._run_train()
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1285, in _run_train
    self.fit_loop.run()
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 270, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 203, in advance
    batch_output = self.batch_loop.run(kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 87, in advance
    outputs = self.optimizer_loop.run(optimizers, kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 201, in advance
    result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 248, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, kwargs.get("batch_idx", 0), closure)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 358, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1552, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py", line 1673, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 216, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 153, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torch/optim/optimizer.py", line 88, in wrapper
    return func(*args, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torch/optim/adamw.py", line 92, in step
    loss = closure()
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 138, in _wrap_closure
    closure_result = closure()
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 132, in closure
    step_output = self._step_fn()
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 407, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *kwargs.values())
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1706, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 358, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/public/sdc/yfzhang/git_sdc/BEVContrast/downstream/train_downstream_semseg.py", line 182, in training_step
    predictions = self.forward(train_batch)
  File "/public/sdc/yfzhang/git_sdc/BEVContrast/downstream/train_downstream_semseg.py", line 121, in forward
    return self.net(data)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/public/sdc/yfzhang/git_sdc/BEVContrast/downstream/networks/backbone/torchsparse/minkunet.py", line 277, in forward
    outputs = super().forward(input)
  File "/public/sdc/yfzhang/git_sdc/BEVContrast/downstream/networks/backbone/torchsparse/minkunet.py", line 251, in forward
    y4 = self.up4[1](y4)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/public/sdc/yfzhang/git_sdc/BEVContrast/downstream/networks/backbone/torchsparse/minkunet.py", line 78, in forward
    out = self.relu(self.net(x) + self.downsample(x))
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torchsparse/nn/modules/norm.py", line 13, in forward
    return fapply(input, super().forward)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torchsparse/nn/utils/apply.py", line 12, in fapply
    feats = fn(input.feats, *args, **kwargs)
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 168, in forward
    return F.batch_norm(
  File "/home/yifanzhang_21/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py", line 2282, in batch_norm
    return torch.batch_norm(
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 23.70 GiB total capacity; 1.24 GiB already allocated; 5.44 MiB free; 1.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
